"""
é’ˆå¯¹Bad Caseçš„æ•°æ®å¢å¼ºç­–ç•¥
åŸºäºé”™è¯¯åˆ†æç»“æœï¼Œå¯¹éš¾æ ·æœ¬è¿›è¡Œé’ˆå¯¹æ€§å¢å¼º
"""
import random
import re
from typing import List, Dict
import pandas as pd
import numpy as np


class BadCaseAugmenter:
    """é’ˆå¯¹Bad Caseçš„æ•°æ®å¢å¼ºå™¨"""
    
    def __init__(self, bad_cases_csv='analysis_results/bad_cases.csv'):
        """
        Args:
            bad_cases_csv: bad caseåˆ†æç»“æœCSVæ–‡ä»¶
        """
        self.bad_cases = pd.read_csv(bad_cases_csv) if bad_cases_csv else None
        
        # æƒ…æ„Ÿè¯å…¸ï¼ˆç”¨äºåŒä¹‰è¯æ›¿æ¢ï¼Œä¿æŒæƒ…æ„Ÿå€¾å‘ï¼‰
        self.positive_words = {
            'good': ['great', 'excellent', 'wonderful', 'amazing', 'fantastic'],
            'like': ['love', 'enjoy', 'appreciate', 'adore'],
            'happy': ['joyful', 'delighted', 'pleased', 'cheerful'],
            'best': ['finest', 'greatest', 'top', 'superior'],
            'beautiful': ['gorgeous', 'stunning', 'lovely', 'attractive']
        }
        
        self.negative_words = {
            'bad': ['awful', 'terrible', 'horrible', 'poor'],
            'hate': ['dislike', 'despise', 'detest'],
            'sad': ['unhappy', 'depressed', 'miserable', 'sorrowful'],
            'worst': ['poorest', 'weakest', 'inferior'],
            'ugly': ['unattractive', 'hideous', 'unsightly']
        }
    
    def augment_text(self, text: str, label: str, methods: List[str] = None) -> List[str]:
        """
        å¯¹æ–‡æœ¬è¿›è¡Œå¢å¼º
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            label: æƒ…æ„Ÿæ ‡ç­¾ (positive/negative/neutral)
            methods: å¢å¼ºæ–¹æ³•åˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨æ‰€æœ‰æ–¹æ³•
        
        Returns:
            augmented_texts: å¢å¼ºåçš„æ–‡æœ¬åˆ—è¡¨
        """
        if methods is None:
            methods = ['synonym', 'insert', 'delete', 'swap']
        
        augmented = []
        
        for method in methods:
            if method == 'synonym':
                aug_text = self.synonym_replacement(text, label)
                if aug_text != text:
                    augmented.append(aug_text)
            
            elif method == 'insert':
                aug_text = self.random_insertion(text, label)
                augmented.append(aug_text)
            
            elif method == 'delete':
                aug_text = self.random_deletion(text)
                augmented.append(aug_text)
            
            elif method == 'swap':
                aug_text = self.random_swap(text)
                augmented.append(aug_text)
        
        return augmented
    
    def synonym_replacement(self, text: str, label: str, n: int = 2) -> str:
        """åŒä¹‰è¯æ›¿æ¢ï¼ˆä¿æŒæƒ…æ„Ÿå€¾å‘ï¼‰"""
        # å¤„ç†éå­—ç¬¦ä¸²æ–‡æœ¬
        if not isinstance(text, str) or not text.strip():
            return text if isinstance(text, str) else ""
        
        words = text.split()
        
        # é€‰æ‹©åˆé€‚çš„åŒä¹‰è¯è¯å…¸
        if label == 'positive':
            synonym_dict = self.positive_words
        elif label == 'negative':
            synonym_dict = self.negative_words
        else:
            return text  # neutralä¸åšæ›¿æ¢
        
        # éšæœºæ›¿æ¢nä¸ªè¯
        replaced = 0
        for i in range(len(words)):
            word_lower = words[i].lower()
            if word_lower in synonym_dict and replaced < n:
                synonyms = synonym_dict[word_lower]
                words[i] = random.choice(synonyms)
                replaced += 1
        
        return ' '.join(words)
    
    def random_insertion(self, text: str, label: str, n: int = 1) -> str:
        """éšæœºæ’å…¥æƒ…æ„Ÿè¯"""
        words = text.split()
        
        # é€‰æ‹©æƒ…æ„Ÿè¯
        if label == 'positive':
            insert_words = ['really', 'very', 'so', 'absolutely', 'definitely']
        elif label == 'negative':
            insert_words = ['really', 'very', 'so', 'absolutely', 'totally']
        else:
            return text
        
        for _ in range(n):
            insert_word = random.choice(insert_words)
            insert_pos = random.randint(0, len(words))
            words.insert(insert_pos, insert_word)
        
        return ' '.join(words)
    
    def random_deletion(self, text: str, p: float = 0.1) -> str:
        """éšæœºåˆ é™¤è¯ï¼ˆä¸åˆ é™¤æƒ…æ„Ÿè¯ï¼‰"""
        words = text.split()
        
        if len(words) == 1:
            return text
        
        # ä¿æŠ¤çš„æƒ…æ„Ÿè¯
        protected = {'good', 'bad', 'great', 'terrible', 'love', 'hate', 
                    'like', 'dislike', 'best', 'worst', 'not', 'no'}
        
        new_words = []
        for word in words:
            if word.lower() not in protected and random.random() > p:
                new_words.append(word)
            else:
                new_words.append(word)
        
        if len(new_words) == 0:
            return random.choice(words)
        
        return ' '.join(new_words)
    
    def random_swap(self, text: str, n: int = 1) -> str:
        """éšæœºäº¤æ¢è¯åº"""
        words = text.split()
        
        if len(words) < 2:
            return text
        
        for _ in range(n):
            idx1, idx2 = random.sample(range(len(words)), 2)
            words[idx1], words[idx2] = words[idx2], words[idx1]
        
        return ' '.join(words)
    
    def augment_bad_cases(self, output_file: str, augment_factor: int = 3, data_dir: str = 'data', min_confidence: float = 0.0):
        """
        å¯¹bad casesè¿›è¡Œæ•°æ®å¢å¼º
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            augment_factor: æ¯ä¸ªbad caseå¢å¼ºçš„å€æ•°ï¼ˆé»˜è®¤3å€ï¼Œé™ä½å™ªå£°ï¼‰
            data_dir: æ•°æ®ç›®å½•ï¼Œç”¨äºæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œåªå¢å¼ºé«˜ç½®ä¿¡åº¦é”™è¯¯ï¼ˆ0.0=å…¨éƒ¨ï¼Œ0.7=é«˜ç½®ä¿¡åº¦ï¼‰
        """
        if self.bad_cases is None:
            print("âš ï¸ No bad cases loaded!")
            return
        
        augmented_data = []
        skipped_count = 0
        filtered_by_confidence = 0
        
        for _, row in self.bad_cases.iterrows():
            # ç½®ä¿¡åº¦è¿‡æ»¤ï¼ˆä½¿ç”¨confidenceå­—æ®µï¼‰
            if 'confidence' in row and row['confidence'] < min_confidence:
                filtered_by_confidence += 1
                continue
                
            guid = row['guid']
            text = row['text']
            label = row['true_label']
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            txt_path = os.path.join(data_dir, f"{guid}.txt")
            img_path = os.path.join(data_dir, f"{guid}.jpg")
            
            if not os.path.exists(txt_path) or not os.path.exists(img_path):
                skipped_count += 1
                continue
            
            # è·³è¿‡ç©ºæ–‡æœ¬æˆ–æ— æ•ˆæ•°æ®
            if pd.isna(text) or not isinstance(text, str) or len(str(text).strip()) == 0:
                skipped_count += 1
                continue
            
            # ç¡®ä¿textæ˜¯å­—ç¬¦ä¸²
            text = str(text)
            
            # åŸå§‹æ ·æœ¬
            augmented_data.append({
                'guid': guid,
                'text': text,
                'tag': label,
                'source': 'original_bad_case'
            })
            
            # å¢å¼ºæ ·æœ¬ï¼ˆé‡ç”¨åŸå§‹GUIDä»¥å¤ç”¨å›¾åƒæ–‡ä»¶ï¼‰
            for i in range(augment_factor):
                aug_texts = self.augment_text(text, label)
                for j, aug_text in enumerate(aug_texts):
                    augmented_data.append({
                        'guid': guid,  # é‡ç”¨åŸå§‹GUIDï¼Œå¤ç”¨å›¾åƒæ–‡ä»¶
                        'text': aug_text,
                        'tag': label,
                        'source': f'augmented_bad_case_method_{j}'
                    })
        
        # ä¿å­˜ï¼ˆä½¿ç”¨åˆ¶è¡¨ç¬¦åˆ†éš”ï¼Œé¿å…æ–‡æœ¬ä¸­çš„é€—å·å¹²æ‰°ï¼‰
        if not augmented_data:
            print("âš ï¸ No valid samples to save!")
            return
        
        with open(output_file, 'w', encoding='utf-8') as f:
            for sample in augmented_data:
                f.write(f"{sample['guid']}\t{sample['text']}\t{sample['tag']}\n")
        
        valid_originals = len([d for d in augmented_data if d['source'] == 'original_bad_case'])
        
        print(f"\nå¢å¼ºç»Ÿè®¡:")
        print(f"  åŸå§‹bad cases: {len(self.bad_cases)}")
        if min_confidence > 0:
            print(f"  ç½®ä¿¡åº¦è¿‡æ»¤: {filtered_by_confidence} (é˜ˆå€¼>{min_confidence:.2f})")
        print(f"  è·³è¿‡æ ·æœ¬: {skipped_count} (æ–‡ä»¶ç¼ºå¤±æˆ–æ— æ•ˆ)")
        print(f"  æœ‰æ•ˆåŸå§‹æ ·æœ¬: {valid_originals}")
        print(f"  å¢å¼ºåæ€»æ ·æœ¬: {len(augmented_data)}")
        print(f"  å¢å¼ºæ ·æœ¬æ•°: {len(augmented_data) - valid_originals}")
        print(f"  å¢å¼ºå€ç‡: {(len(augmented_data) / valid_originals):.1f}x" if valid_originals > 0 else "0x")
        print(f"âœ“ å·²ä¿å­˜åˆ°: {output_file}")


class ImprovedTextPreprocessor:
    """æ”¹è¿›çš„æ–‡æœ¬é¢„å¤„ç†å™¨"""
    
    def __init__(self):
        # Emojiæƒ…æ„Ÿæ˜ å°„
        self.emoji_sentiment = {
            'ğŸ˜Š': ' happy ', 'ğŸ˜ƒ': ' happy ', 'ğŸ˜': ' happy ', 'ğŸ™‚': ' happy ',
            'ğŸ˜¢': ' sad ', 'ğŸ˜­': ' sad ', 'ğŸ˜': ' sad ',
            'ğŸ˜¡': ' angry ', 'ğŸ˜ ': ' angry ',
            'â¤ï¸': ' love ', 'ğŸ’•': ' love ', 'ğŸ’–': ' love ',
            'ğŸ‘': ' good ', 'ğŸ‘': ' bad ',
            'ğŸ˜': ' love ', 'ğŸ¥°': ' love ',
            'ğŸ¤”': ' thinking ', 'ğŸ˜•': ' confused ',
            'ğŸ˜‚': ' laugh ', 'ğŸ¤£': ' laugh ',
            'ğŸ”¥': ' amazing ', 'â­': ' great ',
        }
        
        # ç¼©å†™æ‰©å±•
        self.contractions = {
            "isn't": "is not", "aren't": "are not", "wasn't": "was not",
            "weren't": "were not", "haven't": "have not", "hasn't": "has not",
            "hadn't": "had not", "won't": "will not", "wouldn't": "would not",
            "don't": "do not", "doesn't": "does not", "didn't": "did not",
            "can't": "cannot", "couldn't": "could not", "shouldn't": "should not",
            "mightn't": "might not", "mustn't": "must not",
            "i'm": "i am", "you're": "you are", "he's": "he is",
            "she's": "she is", "it's": "it is", "we're": "we are",
            "they're": "they are", "i've": "i have", "you've": "you have",
            "we've": "we have", "they've": "they have",
            "i'd": "i would", "you'd": "you would", "he'd": "he would",
            "she'd": "she would", "we'd": "we would", "they'd": "they would",
            "i'll": "i will", "you'll": "you will", "he'll": "he will",
            "she'll": "she will", "we'll": "we will", "they'll": "they will",
        }
    
    def preprocess(self, text: str) -> str:
        """æ”¹è¿›çš„é¢„å¤„ç†æµç¨‹"""
        # 1. è½¬emojiä¸ºæƒ…æ„Ÿè¯
        text = self.convert_emoji_to_sentiment(text)
        
        # 2. æ‰©å±•ç¼©å†™
        text = self.expand_contractions(text)
        
        # 3. æ¸…ç†ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™é‡è¦æ ‡ç‚¹ï¼‰
        text = self.clean_text(text)
        
        # 4. å¤„ç†é‡å¤å­—ç¬¦
        text = self.reduce_lengthening(text)
        
        return text
    
    def convert_emoji_to_sentiment(self, text: str) -> str:
        """å°†emojiè½¬æ¢ä¸ºæƒ…æ„Ÿè¯"""
        for emoji, sentiment in self.emoji_sentiment.items():
            text = text.replace(emoji, sentiment)
        return text
    
    def expand_contractions(self, text: str) -> str:
        """æ‰©å±•è‹±æ–‡ç¼©å†™"""
        text_lower = text.lower()
        for contraction, expansion in self.contractions.items():
            text_lower = text_lower.replace(contraction, expansion)
        return text_lower
    
    def clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼ˆä¿ç•™é‡è¦æ ‡ç‚¹ï¼‰"""
        # ç§»é™¤URL
        text = re.sub(r'http\S+|www\S+', '', text)
        
        # ç§»é™¤@mentions
        text = re.sub(r'@\w+', '', text)
        
        # ä¿ç•™é‡è¦æ ‡ç‚¹ï¼š!?.,
        text = re.sub(r'[^\w\s!?.,]', ' ', text)
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def reduce_lengthening(self, text: str) -> str:
        """å‡å°‘é‡å¤å­—ç¬¦ (goooood -> good)"""
        # ä¿ç•™æœ€å¤š2ä¸ªé‡å¤å­—ç¬¦
        pattern = re.compile(r'(.)\1{2,}')
        return pattern.sub(r'\1\1', text)


def main():
    """æ¼”ç¤ºç”¨æ³•"""
    print("="*70)
    print("Bad Caseæ•°æ®å¢å¼ºå·¥å…·")
    print("="*70)
    
    # 1. åˆ†æbad casesï¼ˆéœ€è¦å…ˆè¿è¡Œ analyze_bad_cases.pyï¼‰
    print("\næ­¥éª¤1: ç¡®ä¿å·²è¿è¡Œ bad caseåˆ†æ")
    print("  è¿è¡Œ: python analyze_bad_cases.py")
    
    # 2. å¯¹bad casesè¿›è¡Œå¢å¼º
    print("\næ­¥éª¤2: å¯¹bad casesè¿›è¡Œæ•°æ®å¢å¼º")
    try:
        augmenter = BadCaseAugmenter('analysis_results/bad_cases.csv')
        augmenter.augment_bad_cases(
            output_file='data/augmented_bad_cases.txt',
            augment_factor=2,  # æ¯ä¸ªbad caseå¢å¼º2å€ï¼ˆé¿å…è¿‡æ‹Ÿåˆï¼‰
            data_dir=r'D:\å½“ä»£äººå·¥æ™ºèƒ½\project5\data',  # å®é™…æ•°æ®ç›®å½•
            min_confidence=0.7  # åªå¢å¼ºé«˜ç½®ä¿¡åº¦é”™è¯¯
        )
    except FileNotFoundError:
        print("âš ï¸ æœªæ‰¾åˆ°bad_cases.csvï¼Œè¯·å…ˆè¿è¡Œ analyze_bad_cases.py")
        print("æ¼”ç¤ºå¢å¼ºæ•ˆæœ:")
        
        # æ¼”ç¤º
        augmenter = BadCaseAugmenter(bad_cases_csv=None)
        demo_text = "This movie is really good and I like it"
        print(f"\nåŸå§‹: {demo_text}")
        print("å¢å¼ºç»“æœ:")
        for i, aug in enumerate(augmenter.augment_text(demo_text, 'positive'), 1):
            print(f"  {i}. {aug}")
    
    # 3. æ¼”ç¤ºæ”¹è¿›çš„é¢„å¤„ç†
    print("\næ­¥éª¤3: æ”¹è¿›çš„æ–‡æœ¬é¢„å¤„ç†")
    preprocessor = ImprovedTextPreprocessor()
    
    demo_texts = [
        "I looooove this!!! ğŸ˜ğŸ˜ğŸ˜",
        "It's soooo bad ğŸ˜­ I can't believe it",
        "Check out this link: http://example.com @user",
    ]
    
    for text in demo_texts:
        processed = preprocessor.preprocess(text)
        print(f"  åŸå§‹: {text}")
        print(f"  å¤„ç†: {processed}\n")


if __name__ == '__main__':
    import os
    os.makedirs('data', exist_ok=True)
    os.makedirs('analysis_results', exist_ok=True)
    main()
