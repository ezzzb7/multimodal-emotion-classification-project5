"""
å®Œæ•´çš„æ•°æ®é¢„å¤„ç†ä¸å¢å¼ºå®éªŒ
æŒ‰ç…§å®éªŒè¦æ±‚ï¼šæ•°æ®é¢„å¤„ç†ä¸Šå¯¹æ–‡æœ¬è¿›è¡Œæ¸…æ´—ã€å¯¹å›¾ç‰‡è¿›è¡Œå¢å¼º

å®éªŒè®¾è®¡ï¼š
1. åŸºçº¿ï¼šæ— ä»»ä½•é¢„å¤„ç†
2. æ–‡æœ¬æ¸…æ´—ï¼šURLç§»é™¤ã€@mentionsç§»é™¤ã€ç‰¹æ®Šå­—ç¬¦å¤„ç†
3. å›¾åƒå¢å¼ºï¼šRandomCropã€ColorJitterã€RandomHorizontalFlip
4. å…¨éƒ¨åº”ç”¨ï¼šæ–‡æœ¬æ¸…æ´— + å›¾åƒå¢å¼º
"""
import os
import sys
import re
import time
import json
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from transformers import get_linear_schedule_with_warmup, DistilBertTokenizer
import torchvision.transforms as transforms
from tqdm import tqdm

sys.path.insert(0, os.path.dirname(__file__))

from run_experiment_optimized import OptimizedMultimodalClassifier, OPTIMIZED_CONFIG
from utils.train_utils import set_seed, compute_metrics, EarlyStopping


# ========== æ–­ç‚¹ç»­ä¼  ==========
CHECKPOINT_FILE = 'experiments/data_aug_checkpoint.json'


def load_checkpoint():
    if os.path.exists(CHECKPOINT_FILE):
        with open(CHECKPOINT_FILE, 'r') as f:
            return json.load(f)
    return {'completed': [], 'results': []}


def save_checkpoint(data):
    os.makedirs(os.path.dirname(CHECKPOINT_FILE), exist_ok=True)
    with open(CHECKPOINT_FILE, 'w') as f:
        json.dump(data, f, indent=2)


# ========== æ–‡æœ¬æ¸…æ´—å‡½æ•° ==========
def clean_text_basic(text):
    """åŸºç¡€æ–‡æœ¬æ¸…æ´—"""
    if not isinstance(text, str):
        return ""
    return text.strip()


def clean_text_advanced(text):
    """é«˜çº§æ–‡æœ¬æ¸…æ´—"""
    if not isinstance(text, str):
        return ""
    
    # ç§»é™¤URL
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)
    
    # ç§»é™¤@mentions
    text = re.sub(r'@\w+', '', text)
    
    # ä¿ç•™#hashtagçš„æ–‡å­—éƒ¨åˆ†
    text = re.sub(r'#(\w+)', r'\1', text)
    
    # ç§»é™¤å¤šä½™ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™åŸºæœ¬æ ‡ç‚¹ï¼‰
    text = re.sub(r'[^\w\s.,!?\'"-]', '', text)
    
    return text.strip()


# ========== å›¾åƒTransform ==========
# åŸºç¡€transformï¼ˆæ— å¢å¼ºï¼‰
BASIC_TRANSFORM = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# å¢å¼ºtransform
AUGMENTED_TRANSFORM = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop(224),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# éªŒè¯ç”¨transformï¼ˆå§‹ç»ˆæ— å¢å¼ºï¼‰
VAL_TRANSFORM = BASIC_TRANSFORM


# ========== æ•°æ®é›† ==========
class PreprocessedDataset(Dataset):
    """æ”¯æŒä¸åŒé¢„å¤„ç†æ–¹å¼çš„æ•°æ®é›†"""
    
    def __init__(self, data_dir, split_file, image_transform, text_clean_fn):
        self.data_dir = data_dir
        self.image_transform = image_transform
        self.text_clean_fn = text_clean_fn
        
        self.samples = []
        self.label_map = {'positive': 0, 'negative': 1, 'neutral': 2}
        
        with open(split_file, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split(',')
                if len(parts) >= 2:
                    guid = parts[0]
                    label = parts[1]
                    self.samples.append((guid, self.label_map.get(label, 0)))
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        guid, label = self.samples[idx]
        
        # åŠ è½½æ–‡æœ¬
        text_path = os.path.join(self.data_dir, f"{guid}.txt")
        try:
            with open(text_path, 'r', encoding='utf-8', errors='ignore') as f:
                text = f.read().strip()
        except:
            text = ""
        
        # åº”ç”¨æ–‡æœ¬æ¸…æ´—
        text = self.text_clean_fn(text)
        
        # åŠ è½½å›¾åƒ
        image_path = os.path.join(self.data_dir, f"{guid}.jpg")
        try:
            image = Image.open(image_path).convert('RGB')
            image = self.image_transform(image)
        except:
            image = torch.zeros(3, 224, 224)
        
        return {
            'guid': guid,
            'text': text,
            'image': image,
            'label': label
        }


def run_preprocessing_experiment(exp_id, exp_name, train_img_transform, text_clean_fn, 
                                  use_best_hyperparams=True):
    """è¿è¡Œå•ä¸ªé¢„å¤„ç†å®éªŒ"""
    
    print(f"\n{'='*60}")
    print(f"[{exp_id}] {exp_name}")
    print(f"{'='*60}")
    
    # ä½¿ç”¨æœ€ä½³è¶…å‚æ•°ï¼ˆHP1: dropout=0.2ï¼‰
    config = OPTIMIZED_CONFIG.copy()
    if use_best_hyperparams:
        config['dropout'] = 0.2  # HP1æœ€ä½³é…ç½®
    
    set_seed(config['seed'])
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"è®¾å¤‡: {device}")
    
    # åŠ è½½tokenizer
    print("åŠ è½½ Tokenizer...")
    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', local_files_only=True)
    
    # åˆ›å»ºæ•°æ®é›†
    print("åˆ›å»ºæ•°æ®é›†...")
    train_dataset = PreprocessedDataset(
        data_dir=config['data_dir'],
        split_file='splits/train_split.txt',
        image_transform=train_img_transform,
        text_clean_fn=text_clean_fn
    )
    val_dataset = PreprocessedDataset(
        data_dir=config['data_dir'],
        split_file='splits/val_split.txt',
        image_transform=VAL_TRANSFORM,  # éªŒè¯é›†ä¸å¢å¼º
        text_clean_fn=text_clean_fn  # ä½†æ–‡æœ¬æ¸…æ´—ä¿æŒä¸€è‡´
    )
    
    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], 
                              shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], 
                            shuffle=False, num_workers=0)
    
    print(f"  è®­ç»ƒé›†: {len(train_dataset)}, éªŒè¯é›†: {len(val_dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºæ¨¡å‹...")
    model = OptimizedMultimodalClassifier(
        num_classes=3,
        feature_dim=config['feature_dim'],
        fusion_type='cross_attention',
        dropout=config['dropout'],
        unfreeze_text_layers=config['unfreeze_text_layers'],
        unfreeze_image_layers=config['unfreeze_image_layers']
    ).to(device)
    
    # è®­ç»ƒè®¾ç½®
    class_weights = torch.FloatTensor([1.0, 1.5, 3.0]).to(device)
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    
    param_groups = model.get_param_groups(
        lr_pretrained=config['lr_pretrained'],
        lr_fusion=config['lr_fusion'],
        lr_classifier=config['lr_classifier']
    )
    optimizer = AdamW(param_groups, weight_decay=config['weight_decay'])
    
    total_steps = len(train_loader) * 15 // config['accumulation_steps']
    warmup_steps = int(total_steps * config['warmup_ratio'])
    scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)
    
    early_stopping = EarlyStopping(patience=7, mode='max')
    
    # è®­ç»ƒ
    print("\nå¼€å§‹è®­ç»ƒ...")
    import sys
    sys.stdout.flush()
    
    best_val_acc = 0
    best_val_f1 = 0
    best_epoch = 0
    start_time = time.time()
    
    for epoch in range(15):
        model.train()
        batch_count = 0
        print(f"  Epoch {epoch+1}/15 [", end="", flush=True)
        
        for step, batch in enumerate(train_loader):
            texts = batch['text']
            images = batch['image'].to(device)
            labels = batch['label'].to(device)
            
            encoded = tokenizer(list(texts), padding=True, truncation=True, 
                              max_length=128, return_tensors='pt')
            input_ids = encoded['input_ids'].to(device)
            attention_mask = encoded['attention_mask'].to(device)
            
            logits = model(input_ids, attention_mask, images)
            loss = criterion(logits, labels) / config['accumulation_steps']
            loss.backward()
            
            if (step + 1) % config['accumulation_steps'] == 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), config['max_grad_norm'])
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()
            
            batch_count += 1
            if batch_count % 20 == 0:
                print(".", end="", flush=True)
        
        print("] ", end="", flush=True)
        
        # éªŒè¯
        model.eval()
        val_preds, val_labels_list = [], []
        
        with torch.no_grad():
            for batch in val_loader:
                texts = batch['text']
                images = batch['image'].to(device)
                labels = batch['label'].to(device)
                
                encoded = tokenizer(list(texts), padding=True, truncation=True,
                                  max_length=128, return_tensors='pt')
                input_ids = encoded['input_ids'].to(device)
                attention_mask = encoded['attention_mask'].to(device)
                
                logits = model(input_ids, attention_mask, images)
                val_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())
                val_labels_list.extend(labels.cpu().numpy())
        
        val_metrics = compute_metrics(val_preds, val_labels_list)
        print(f"Val Acc: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1']:.4f}", flush=True)
        
        if val_metrics['accuracy'] > best_val_acc:
            best_val_acc = val_metrics['accuracy']
            best_val_f1 = val_metrics['f1']
            best_epoch = epoch + 1
            
            os.makedirs('experiments/checkpoints', exist_ok=True)
            torch.save(model.state_dict(), f'experiments/checkpoints/{exp_id}_best.pth')
            print(f"    âœ“ æ–°æœ€ä½³!", flush=True)
        
        if early_stopping(val_metrics['accuracy'], epoch):
            print(f"  Early stopping at epoch {epoch+1}")
            break
    
    training_time = (time.time() - start_time) / 60
    
    result = {
        'exp_id': exp_id,
        'exp_name': exp_name,
        'val_acc': best_val_acc,
        'val_f1': best_val_f1,
        'best_epoch': best_epoch,
        'training_time': training_time
    }
    
    print(f"\nå®éªŒ {exp_id} å®Œæˆ!")
    print(f"  æœ€ä½³ Val Acc: {best_val_acc:.4f} (Epoch {best_epoch})")
    print(f"  è®­ç»ƒæ—¶é—´: {training_time:.1f} åˆ†é’Ÿ")
    
    return result


def run_all_preprocessing_experiments():
    """è¿è¡Œæ‰€æœ‰é¢„å¤„ç†å®éªŒ"""
    
    print("\n" + "="*70)
    print("æ•°æ®é¢„å¤„ç†ä¸å¢å¼ºå¯¹æ¯”å®éªŒ")
    print("="*70)
    
    # åŠ è½½æ–­ç‚¹
    checkpoint = load_checkpoint()
    completed = set(checkpoint.get('completed', []))
    results = checkpoint.get('results', [])
    
    if completed:
        print(f"âœ“ ä»æ–­ç‚¹æ¢å¤ï¼Œå·²å®Œæˆ {len(completed)} ä¸ªå®éªŒ")
    
    experiments = [
        # (exp_id, exp_name, train_img_transform, text_clean_fn)
        ('DA1', 'åŸºçº¿(æ— é¢„å¤„ç†)', BASIC_TRANSFORM, clean_text_basic),
        ('DA2', 'ä»…æ–‡æœ¬æ¸…æ´—', BASIC_TRANSFORM, clean_text_advanced),
        ('DA3', 'ä»…å›¾åƒå¢å¼º', AUGMENTED_TRANSFORM, clean_text_basic),
        ('DA4', 'æ–‡æœ¬æ¸…æ´—+å›¾åƒå¢å¼º', AUGMENTED_TRANSFORM, clean_text_advanced),
    ]
    
    for exp_id, exp_name, img_transform, text_fn in experiments:
        if exp_id in completed:
            print(f"\n[{exp_id}] å·²å®Œæˆï¼Œè·³è¿‡")
            continue
        
        try:
            result = run_preprocessing_experiment(exp_id, exp_name, img_transform, text_fn)
            results.append(result)
            completed.add(exp_id)
            
            save_checkpoint({
                'completed': list(completed),
                'results': results
            })
            print(f"  âœ“ æ–­ç‚¹å·²ä¿å­˜")
            
        except Exception as e:
            print(f"  âŒ å®éªŒå¤±è´¥: {e}")
            save_checkpoint({
                'completed': list(completed),
                'results': results
            })
            raise
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*70)
    print("æ•°æ®é¢„å¤„ç†å®éªŒç»“æœ")
    print("="*70)
    print(f"{'ID':<8} {'é¢„å¤„ç†æ–¹å¼':<25} {'Val Acc':<10} {'Val F1':<10}")
    print("-"*53)
    
    for r in sorted(results, key=lambda x: -x['val_acc']):
        print(f"{r['exp_id']:<8} {r['exp_name']:<25} {r['val_acc']:.4f}     {r['val_f1']:.4f}")
    
    if results:
        best = max(results, key=lambda x: x['val_acc'])
        print(f"\nğŸ† æœ€ä½³é¢„å¤„ç†æ–¹å¼: {best['exp_name']}")
        print(f"   Val Acc: {best['val_acc']:.4f}")
    
    return results


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®é¢„å¤„ç†å®éªŒ')
    parser.add_argument('--run', action='store_true', help='è¿è¡Œæ‰€æœ‰é¢„å¤„ç†å®éªŒ')
    
    args = parser.parse_args()
    
    if args.run:
        run_all_preprocessing_experiments()
    else:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  py -3.11 run_data_preprocessing_exp.py --run")
