"""
æ”¹è¿›çš„Bad Caseåˆ†æå·¥å…· - ä½¿ç”¨è®­ç»ƒé›†é¿å…æ•°æ®æ³„æ¼
æ¨èå®è·µï¼šä½¿ç”¨è®­ç»ƒé›†é«˜ç½®ä¿¡åº¦é”™è¯¯è¿›è¡Œå¢å¼º
"""

import os
import sys
import argparse
import torch
import pandas as pd
from collections import Counter
import numpy as np

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.multimodal_model import MultimodalClassifier
from data.data_loader import get_data_loaders


def analyze_bad_cases_improved(checkpoint_path, data_dir, output_dir='analysis_results',
                               split='train', min_confidence=0.7):
    """
    æ”¹è¿›çš„Bad Caseåˆ†æ
    
    Args:
        checkpoint_path: æ¨¡å‹checkpointè·¯å¾„
        data_dir: æ•°æ®ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        split: 'train' (æ¨èï¼Œé¿å…æ•°æ®æ³„æ¼) æˆ– 'val'
        min_confidence: åªåˆ†æé¢„æµ‹ç½®ä¿¡åº¦>æ­¤å€¼çš„é”™è¯¯æ ·æœ¬
    
    æ¨èé…ç½®:
        - split='train': ä½¿ç”¨è®­ç»ƒé›†bad casesï¼Œé¿å…éªŒè¯é›†ä¿¡æ¯æ³„æ¼
        - min_confidence=0.7: åªå¢å¼ºé«˜ç½®ä¿¡åº¦é”™è¯¯ï¼ˆæ¨¡å‹ç¡®ä¿¡ä½†é”™äº†çš„æ ·æœ¬ï¼‰
    """
    print("=" * 70)
    print("æ”¹è¿›çš„Bad Caseåˆ†æå·¥å…·")
    print("=" * 70)
    print(f"\né…ç½®:")
    print(f"  - æ•°æ®é›†: {split} (æ¨èä½¿ç”¨trainé¿å…æ•°æ®æ³„æ¼)")
    print(f"  - æœ€å°ç½®ä¿¡åº¦: {min_confidence} (åªåˆ†æé«˜ç½®ä¿¡åº¦é”™è¯¯)")
    print(f"  - Checkpoint: {checkpoint_path}\n")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    print("åŠ è½½æ•°æ®...")
    train_label_file = os.path.join(data_dir, 'train.txt')
    train_loader, val_loader, _ = get_data_loaders(
        data_dir=data_dir,
        train_label_file=train_label_file,
        batch_size=8
    )
    dataloader = train_loader if split == 'train' else val_loader
    
    # åŠ è½½æ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = MultimodalClassifier(
        num_classes=3,
        fusion_type='early',
        freeze_encoders=True
    )
    
    print(f"\nåŠ è½½checkpoint: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    print(f"âœ“ Checkpoint loaded: epoch {checkpoint['epoch']}, best_acc {checkpoint['best_acc']:.4f}")
    
    device = torch.device('cpu')
    model.to(device)
    model.eval()
    
    # åˆ†æé”™è¯¯
    print(f"\nåˆ†æ{split}é›†é”™è¯¯ï¼ˆæœ€å°ç½®ä¿¡åº¦: {min_confidence}ï¼‰...")
    bad_cases = []
    label_names = ['positive', 'negative', 'neutral']
    
    with torch.no_grad():
        for batch in dataloader:
            # å‰å‘ä¼ æ’­
            logits = model(batch)
            probs = torch.softmax(logits, dim=1)
            preds = torch.argmax(logits, dim=1)
            
            # æ‰¾å‡ºé”™è¯¯æ ·æœ¬
            errors = preds != batch['label']
            
            for i in range(len(batch['label'])):
                if errors[i]:
                    confidence = probs[i, preds[i]].item()
                    
                    # åªä¿å­˜é«˜ç½®ä¿¡åº¦é”™è¯¯
                    if confidence >= min_confidence:
                        guid = batch['guid'][i]
                        if isinstance(guid, torch.Tensor):
                            guid = guid.item()
                        
                        bad_cases.append({
                            'guid': guid,
                            'text': batch['text'][i],
                            'true_label': label_names[batch['label'][i].item()],
                            'pred_label': label_names[preds[i].item()],
                            'confidence': confidence
                        })
    
    print(f"âœ“ æ‰¾åˆ° {len(bad_cases)} ä¸ªé«˜ç½®ä¿¡åº¦é”™è¯¯æ ·æœ¬ï¼ˆç½®ä¿¡åº¦ > {min_confidence}ï¼‰")
    
    if len(bad_cases) == 0:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„bad cases")
        return
    
    # ä¿å­˜bad cases
    output_path = os.path.join(output_dir, 'bad_cases.csv')
    df = pd.DataFrame(bad_cases)
    df.to_csv(output_path, index=False, encoding='utf-8')
    print(f"âœ“ Bad cases saved to: {output_path}")
    
    # ç»Ÿè®¡åˆ†æ
    print("\n" + "=" * 70)
    print("Bad Caseåˆ†ææŠ¥å‘Š")
    print("=" * 70)
    
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  - æ•°æ®é›†: {split}")
    print(f"  - é”™è¯¯æ ·æœ¬æ•°: {len(bad_cases)}")
    print(f"  - å¹³å‡é¢„æµ‹ç½®ä¿¡åº¦: {np.mean([c['confidence'] for c in bad_cases]):.4f}")
    
    # æ··æ·†åˆ†æ
    print(f"\nğŸ”€ æ··æ·†çŸ©é˜µ (é”™è¯¯ç±»å‹åˆ†å¸ƒ):")
    confusion = Counter([(c['true_label'], c['pred_label']) for c in bad_cases])
    for (true_label, pred_label), count in confusion.most_common():
        pct = count / len(bad_cases) * 100
        print(f"  {true_label} â†’ {pred_label}: {count} ({pct:.1f}%)")
    
    # æ–‡æœ¬é•¿åº¦åˆ†æ
    text_lengths = [len(c['text']) for c in bad_cases]
    print(f"\nğŸ“ æ–‡æœ¬é•¿åº¦ç»Ÿè®¡:")
    print(f"  - å¹³å‡é•¿åº¦: {np.mean(text_lengths):.1f} Â± {np.std(text_lengths):.1f}")
    print(f"  - èŒƒå›´: [{min(text_lengths)}, {max(text_lengths)}]")
    
    # é«˜ç½®ä¿¡åº¦é”™è¯¯æ¡ˆä¾‹
    print(f"\nâš ï¸ é«˜ç½®ä¿¡åº¦é”™è¯¯æ¡ˆä¾‹ (Top 5):")
    sorted_cases = sorted(bad_cases, key=lambda x: x['confidence'], reverse=True)
    for i, case in enumerate(sorted_cases[:5], 1):
        print(f"\n  {i}. GUID: {case['guid']}")
        print(f"     çœŸå®: {case['true_label']} | é¢„æµ‹: {case['pred_label']} (ç½®ä¿¡åº¦: {case['confidence']:.3f})")
        print(f"     æ–‡æœ¬: {case['text'][:100]}...")
    
    print("\n" + "=" * 70)
    
    print(f"\nğŸ’¡ æ•°æ®æ³„æ¼é£é™©è¯„ä¼°:")
    if split == 'val':
        print("  âš ï¸ è­¦å‘Š: ä½¿ç”¨éªŒè¯é›†ä¼šå¯¼è‡´ä¿¡æ¯æ³„æ¼")
        print("  âœ“ å»ºè®®: ä½¿ç”¨è®­ç»ƒé›†bad casesè¿›è¡Œå¢å¼º")
    else:
        print("  âœ“ è‰¯å¥½å®è·µ: ä½¿ç”¨è®­ç»ƒé›†é¿å…äº†éªŒè¯é›†æ³„æ¼")
    
    print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    print(f"  âœ“ æ‰¾åˆ° {len(bad_cases)} ä¸ªé«˜ç½®ä¿¡åº¦é”™è¯¯ï¼ˆæ¨¡å‹ç¡®ä¿¡ä½†é”™äº†ï¼‰")
    print(f"  âœ“ å»ºè®®å¯¹è¿™äº›æ ·æœ¬è¿›è¡Œé€‚åº¦å¢å¼ºï¼ˆ2-3å€ï¼‰")
    print(f"  âœ“ é¿å…è¿‡åº¦å¢å¼ºå¯¼è‡´è¿‡æ‹Ÿåˆ")
    
    print("=" * 70)


def main():
    parser = argparse.ArgumentParser(description='æ”¹è¿›çš„Bad Caseåˆ†æ')
    parser.add_argument('--checkpoint', type=str,
                       default='checkpoints/best_early_multimodal_20260120_195503.pth',
                       help='æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--data_dir', type=str,
                       default=r'D:\å½“ä»£äººå·¥æ™ºèƒ½\project5\data',
                       help='æ•°æ®ç›®å½•')
    parser.add_argument('--split', type=str, default='train',
                       choices=['train', 'val'],
                       help='ä½¿ç”¨å“ªä¸ªæ•°æ®é›†ï¼ˆæ¨ètrainé¿å…æ•°æ®æ³„æ¼ï¼‰')
    parser.add_argument('--min_confidence', type=float, default=0.7,
                       help='æœ€å°é¢„æµ‹ç½®ä¿¡åº¦ï¼ˆåªåˆ†æé«˜ç½®ä¿¡åº¦é”™è¯¯ï¼‰')
    
    args = parser.parse_args()
    
    analyze_bad_cases_improved(
        checkpoint_path=args.checkpoint,
        data_dir=args.data_dir,
        output_dir='analysis_results',
        split=args.split,
        min_confidence=args.min_confidence
    )


if __name__ == '__main__':
    main()
